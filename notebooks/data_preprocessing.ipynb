{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown ; \n",
    "import pandas as pd ; \n",
    "import numpy as np;\n",
    "import math\n",
    "import os\n",
    "# train_log_url = \"https://drive.google.com/file/d/1VebJgr8LlRWeCsAnYA2OK6VzdtsB9L83/view?usp=drive_link\"\n",
    "# gdown.download(url=train_log_url, quiet=False, fuzzy=True)\n",
    "\n",
    "# train_score_url = \"https://drive.google.com/file/d/1VQ05dODI0aKyvu2RB0-WU2hzk4_bqJyw/view?usp=sharing\"\n",
    "# gdown.download(url=train_score_url, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to apply on each row for train_logs\n",
    "def pause_time_to_string(value):\n",
    "    ## If the pause is bigger than 1000(1sec), value/1000 that many pause to column\n",
    "    if math.isnan(value)or value <= 1000 :\n",
    "        return \"\"\n",
    "    else:\n",
    "        sec = round(value/ 1000)\n",
    "        return \" \".join(['pause' for i in range(sec)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(df):\n",
    "    if df['pause_str'] != '':\n",
    "        return df['down_event'] + \" \" + df['pause_str'] \n",
    "    else:\n",
    "        return df['down_event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to generate and return a string of hmm sequence array\n",
    "def genHMMInput(df):\n",
    "    df = df.copy()\n",
    "    ##create a new coulmn that contains pause time\n",
    "    df[\"next_down_time\"] = df[\"down_time\"].shift(-1)\n",
    "    df[\"pause_time\"] = df[\"next_down_time\"] - df[\"down_time\"]\n",
    "    ####create new column pause_str.\n",
    "    df[\"pause_str\"] = df['pause_time'].apply(pause_time_to_string)\n",
    "    df['hmm_input'] = df.apply(combine_columns, axis=1)\n",
    "    mask = df['id'] != df['id'].shift(-1)\n",
    "    mask.iloc[-1] = False\n",
    "    df.loc[mask, 'hmm_input'] += \" K\"\n",
    "    hmm_input = \" \".join(df[\"hmm_input\"].tolist())\n",
    "    return hmm_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df2 = pd.read_csv(\"train_logs.csv\")\n",
    "# df = df2.loc[0:4].copy()\n",
    "# df[\"next_down_time\"] = df[\"down_time\"].shift(-1)\n",
    "# df[\"pause_time\"] = df[\"next_down_time\"] - df[\"down_time\"]\n",
    "# ####create new column pause_str.\n",
    "# df[\"pause_str\"] = df['pause_time'].apply(pause_time_to_string)\n",
    "# df['hmm_input'] = df.apply(combine_columns, axis=1)\n",
    "# mask = df['id'] != df['id'].shift(-1)\n",
    "# mask.iloc[-1] = False\n",
    "# df.loc[mask, 'hmm_input'] += \" K\"\n",
    "# hmm_input = \" \".join(df[\"hmm_input\"].tolist())\n",
    "# hmm_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 486 for score 3.5, train will have 388 and test will have 98\n",
      "Total of 37 for score 6.0, train will have 29 and test will have 8\n",
      "Total of 92 for score 2.0, train will have 73 and test will have 19\n",
      "Total of 501 for score 4.0, train will have 400 and test will have 101\n",
      "Total of 402 for score 4.5, train will have 321 and test will have 81\n",
      "Total of 201 for score 2.5, train will have 160 and test will have 41\n",
      "Total of 179 for score 5.0, train will have 143 and test will have 36\n",
      "Total of 336 for score 3.0, train will have 268 and test will have 68\n",
      "Total of 69 for score 1.5, train will have 55 and test will have 14\n",
      "Total of 128 for score 5.5, train will have 102 and test will have 26\n",
      "Total of 35 for score 1.0, train will have 28 and test will have 7\n",
      "Total of 5 for score 0.5, train will have 4 and test will have 1\n"
     ]
    }
   ],
   "source": [
    "##function that call the above and write them into files\n",
    "def generateFile(logs, score):\n",
    "    train_dfs = []\n",
    "    test_dfs = []\n",
    "    \n",
    "    logs_df = pd.read_csv(logs)\n",
    "    score_df  = pd.read_csv(score)\n",
    "\n",
    "    if not os.path.exists(\"train\"):\n",
    "            os.makedirs(\"train\")\n",
    "    if not os.path.exists(\"test\"):\n",
    "            os.makedirs(\"test\")\n",
    "    ##generate inner join dataframe\n",
    "    log_join_score = pd.merge(logs_df, score_df, on=\"id\", how='inner')\n",
    "    for s in score_df[\"score\"].unique():\n",
    "        ##join log and score dataframe base on id\n",
    "        cur_score_df = log_join_score.loc[log_join_score[\"score\"] == s]\n",
    "        unique_doc_id = cur_score_df[\"id\"].unique()\n",
    "        num_unqiue = len(unique_doc_id)\n",
    "        ##set up randomness and raito for train/test split\n",
    "        np.random.shuffle(unique_doc_id)\n",
    "        split_ratio = 0.8\n",
    "        split_index = int(len(unique_doc_id) * split_ratio)\n",
    "\n",
    "        ##set the ids that are in train set and test set\n",
    "        train_id = unique_doc_id[:split_index]\n",
    "        test_id = unique_doc_id[split_index:]\n",
    "\n",
    "        len_train = len(train_id)\n",
    "        len_test = len(test_id)\n",
    "        print(f\"Total of {num_unqiue} for score {s}, train will have {len_train} and test will have {len_test}\")\n",
    "\n",
    "        ##create df for train and test\n",
    "        train_df = log_join_score[log_join_score['id'].isin(train_id)]\n",
    "        test_df = log_join_score[log_join_score['id'].isin(test_id)]\n",
    "\n",
    "        ##add them to the list\n",
    "        train_dfs.append(train_df)\n",
    "        test_dfs.append(test_df)\n",
    "\n",
    "        for df in train_dfs:\n",
    "            s = str(s)\n",
    "            hmm_input = genHMMInput(df)\n",
    "            with open( \"train/\" +s +\".txt\", 'w') as file:\n",
    "                file.write(hmm_input)\n",
    "        for df in test_dfs:\n",
    "            hmm_input = genHMMInput(df)\n",
    "            with open( \"test/\" +s +\".txt\", 'w') as file:\n",
    "                file.write(hmm_input)\n",
    "    \n",
    "\n",
    "generateFile(\"train_logs.csv\", \"train_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7402306\n"
     ]
    }
   ],
   "source": [
    "with open(\"train/3.5.txt\", \"r\") as file:\n",
    "    print(len(file.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##write only 3.5 to a csv file\n",
    "# logs_df = pd.read_csv(\"train_logs.csv\")\n",
    "# score_df = pd.read_csv(\"train_scores.csv\")\n",
    "# log_join_score = pd.merge(logs_df, score_df, on=\"id\", how='inner')\n",
    "# logs_df[log_join_score['score']==3.5].to_csv(\"35.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"35.csv\")\n",
    "# df[\"next_down_time\"] = df[\"down_time\"].shift(-1)\n",
    "# df[\"pause_time\"] = df[\"next_down_time\"] - df[\"down_time\"]\n",
    "# ####create new column pause_str.\n",
    "# df[\"pause_str\"] = df['pause_time'].apply(pause_time_to_string)\n",
    "# df['hmm_input'] = df.apply(combine_columns, axis=1)\n",
    "# mask = df['id'] != df['id'].shift(-1)\n",
    "# mask.iloc[-1] = False\n",
    "# df.loc[mask, 'hmm_input'] += \" K\"\n",
    "# hmm_input = \" \".join(df[\"hmm_input\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['hmm_input'].str.contains('Ã…')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_name = \"pause_time\"\n",
    "# # plt.scatter(train_logs.index, train_logs[column_name])\n",
    "\n",
    "# # # Add labels and title\n",
    "# # plt.xlabel('Index')\n",
    "# # plt.ylabel(column_name)\n",
    "# # plt.title(f'Scatter Plot of {column_name} vs Index')\n",
    "\n",
    "# # # Show the plot\n",
    "# # # plt.show()\n",
    "\n",
    "# percentiles = [25,50,75,80,85] + list(range(90,101))\n",
    "# # percentiles = list(range(90,101))\n",
    "\n",
    "# # Use the percentile function to calculate the specified percentiles\n",
    "# percentile_values = np.percentile(train_logs[column_name].dropna(), percentiles)\n",
    "# for p, value in zip(percentiles, percentile_values):\n",
    "#     print(f'{p}th percentile: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming you already have a DataFrame named 'df'\n",
    "# # Replace 'column_name' with the actual column you want to plot\n",
    "# column_name = 'action_time'\n",
    "# # train_logs[\"action_time\"] = train_logs[\"action_time\"].astype(int)\n",
    "# mask = (train_logs[\"action_time\"] <=  10000)\n",
    "# df = train_logs[mask]\n",
    "# # Create a scatter plot\n",
    "# plt.scatter(df.index, df[column_name])\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel(column_name)\n",
    "# plt.title(f'Scatter Plot of {column_name} vs Index')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n",
    "# percentiles = list(range(90,101))\n",
    "\n",
    "# # Use the percentile function to calculate the specified percentiles\n",
    "# percentile_values = np.percentile(train_logs[column_name].dropna(), percentiles)\n",
    "# for p, value in zip(percentiles, percentile_values):\n",
    "#     print(f'{p}th percentile: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you already have a DataFrame named 'df'\n",
    "# # Replace 'column_name' with the actual column you want to plot\n",
    "# column_name = ''\n",
    "# # train_logs[\"action_time\"] = train_logs[\"action_time\"].astype(int)\n",
    "# mask = (train_logs[\"action_time\"] <=  10000)\n",
    "# df = train_logs[mask]\n",
    "# # Create a scatter plot\n",
    "# plt.scatter(df.index, df[column_name])\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel(column_name)\n",
    "# plt.title(f'Scatter Plot of {column_name} vs Index')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n",
    "# percentiles = list(range(90,101))\n",
    "\n",
    "# # Use the percentile function to calculate the specified percentiles\n",
    "# percentile_values = np.percentile(train_logs[column_name].dropna(), percentiles)\n",
    "# for p, value in zip(percentiles, percentile_values):\n",
    "#     print(f'{p}th percentile: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##find the gap between down/up time\n",
    "# print(max(train_logs[\"action_time\"]), min(train_logs[\"action_time\"]))\n",
    "\n",
    "# for i, r in train_logs.iterrows():\n",
    "#   cur_event = r[\"down_time\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
